# Nginx

1. ~~~ shell
   #获取nginx镜像
   docker pull nginx
   
   #初始运行nginx
   docker run --name nginx nginx
   
   #获取镜像中的配置和日志信息
   docker cp nginx:/etc/nginx/nginx.conf /mnt/docker/nginx/conf/nginx.conf
   docker cp nginx:/etc/nginx/conf.d /mnt/docker/nginx/conf/conf.d
   docker cp nginx:/usr/share/nginx/html /mnt/docker/nginx/
   
   docker cp nginx4:/etc/nginx/nginx.conf /mnt/docker/nginx4/conf/nginx.conf
   docker cp nginx4:/etc/nginx/conf.d /mnt/docker/nginx4/conf/conf.d
   docker cp nginx4:/usr/share/nginx/html /mnt/docker/nginx4/
   ~~~
   
2. ~~~ nginx
   # 填写配置信息，此处mylb可以转发到两个网关中的一个，采用默认的轮询策略的负载均衡
   upstream mylb{
       server 172.17.0.1:28087 weight=1;
       server 172.17.0.1:28088 weight=1; #网关负载均衡
   }
   server {
       listen       80;
       listen  [::]:80;
       server_name  localhost;
   
       location / {
           root   /usr/share/nginx/html;
           try_files $uri $uri/ /index.html last;
           index  index.html index.htm;
       }
       
       location ^~/api/ {
           proxy_pass http://mylb/;
       }
   
       error_page   500 502 503 504  /50x.html;
       location = /50x.html {
           root   /usr/share/nginx/html;
       }
   }
   ~~~

3. 将Vue打包的dist解压放在 /mnt/docker/nginx/ 目录下

4. ~~~ shell
   #重新启动nginx，代理80端口，并将配置和html挂载到容器内部
   docker stop nginx
   
   docker rm nginx
   
   docker run \
   -p 80:80 \
   --name nginx \
   -v /mnt/docker/nginx/conf/nginx.conf:/etc/nginx/nginx.conf \
   -v /mnt/docker/nginx/conf/conf.d:/etc/nginx/conf.d \
   -v /mnt/docker/nginx/log:/var/log/nginx \
   -v /mnt/docker/nginx/html:/usr/share/nginx/html \
   -e TZ=Asia/Shanghai \
   --privileged=true \
   -d nginx:latest
   
   docker run \
   -p 82:80 \
   --name nginx4 \
   -v /mnt/docker/nginx4/conf/nginx.conf:/etc/nginx/nginx.conf \
   -v /mnt/docker/nginx4/conf/conf.d:/etc/nginx/conf.d \
   -v /mnt/docker/nginx4/log:/var/log/nginx \
   -v /mnt/docker/nginx4/html:/usr/share/nginx/html \
   -e TZ=Asia/Shanghai \
   --privileged=true \
   -d nginx:latest
   ~~~

# Nacos

1. ~~~shell
   #获取nacos镜像
   docker pull nacos/nacos-server
   
   #运行nacos镜像，使用8848端口
   docker run --name nacos -p 8848:8848 -e MODE=standalone nacos/nacos-server
   ~~~

2. 输入 http://47.116.21.188:8848/nacos 进入自带的面板进行访问管理，账号密码默认nacos

# Sentinel

1. 获取sentinel的jar包，此处版本为1.8.1

2. ~~~ shell
   # 运行sentinel的控制面板进行管理，端口8080
   java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard-1.8.1.jar
   ~~~

3. 输入 http://47.116.21.188:9090 进入自带的面板进行访问管理，账号密码默认sentinel

4. 可以对网关的路由进行流控和降级

# SEATA

1. 获取GitHub上SEATA的压缩包。由于Spring Cloud版本为2.2.5.RELEASE，所以使用对应的Tag1.3版本的SEATA

2. 解压缩后进入seata/conf进行一系列配置

3. ~~~shell
   #修改file.conf，将存储模式改为数据库存储，mode="db"
   ......
   store {
     ## store mode: file、db、redis
     mode = "db"
   ......
   ~~~

4. ~~~ shell
   #修改registry.conf，将配置中心的地址改为我们自己的nacos地址
   nacos {
       application = "seata-server"
       serverAddr = "127.0.0.1:8848"
       group = "SEATA_GROUP"
       namespace = ""
       cluster = "default"
       username = "nacos"
       password = "nacos"
     }
   ~~~

5. ~~~ shell
   #新建config.txt，配置seata_server的信息
   # 定义组，应用中也需要对应
   service.vgroupMapping.nacos-demo-group=default
   store.mode=db|redis
   -----db-----
   store.db.datasource=druid
   store.db.dbType=mysql
   store.db.driverClassName=com.mysql.jdbc.Driver
   store.db.url=jdbc:mysql://127.0.0.1:3306/seata_server?useUnicode=true
   store.db.user=root
   store.db.password=123456
   ~~~

6. 创建seata_server数据库，运行GitHub的SEATA仓库中下载的seata_server.sql

7. 给每个分布式的数据库运行Github上的undo_log.sql创建表。

8. ~~~shell
   #运行shell命令，可以自动将config.txt的配置信息注册到nacos的配置中心
   sh nacos-config.sh
   ~~~

9. ~~~ shell
   #运行seata-server
   sh seata-server.sh #默认8091端口
   
   #再运行一个seata服务器放在8092端口，实现集群部署
   sh seata-server.sh -p 8092
   
   #此时两个服务都注册到了nacos中，实现再业务访问seata时实现负载均衡
   ~~~

#  网关微服务

分别运行在28087和28088端口，由Nginx进行转发

~~~shell
nohup java -jar gateway-serv.jar >gateway1.txt --server.port=28087 &
nohup java -jar gateway-serv.jar >gateway2.txt --server.port=28088 &
~~~

 # 业务微服务

教师启动在28082端口，教务在28083端口，学生在28080和28081端口，课程在28084~28086端口。由OpenFeign进行随机访问策略的负载均衡调用

~~~shell
nohup java -jar teacher-serv.jar >teacher.txt --spring.profiles.active = deploy --server.port=28082 &

nohup java -jar office-serv.jar >office.txt --spring.profiles.active = deploy --server.port=28083 &

nohup java -jar student-serv.jar >student1.txt --spring.profiles.active = deploy --server.port=28080 &
nohup java -jar student-serv.jar >student2.txt --spring.profiles.active = deploy --server.port=28081 &

nohup java -jar course-serv.jar >course1.txt --spring.profiles.active = deploy --server.port=28084 &
nohup java -jar course-serv.jar >course2.txt --spring.profiles.active = deploy --server.port=28085 &
nohup java -jar course-serv.jar >course3.txt --spring.profiles.active = deploy --server.port=28086 &
~~~

**注：**在这些微服务打包成jar包时，由于个module之间有依赖关系，故应该首先mvn clean 父组件的module再打包，否则可能打包不成功。